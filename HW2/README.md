# Homework-2: Ensemble Learning

é€™æ˜¯ä¸€å€‹é—œæ–¼ Ensemble Learning çš„æ©Ÿå™¨å­¸ç¿’ä½œæ¥­å¯¦ä½œï¼Œä½¿ç”¨ MNIST å’Œ Fashion MNIST è³‡æ–™é›†é€²è¡Œå¤šé¡åˆ¥åˆ†é¡ã€‚

## ğŸ“‹ ä½œæ¥­è¦æ±‚

### Part 1: MNIST Dataset
- è¼‰å…¥ä¸¦åˆ†å‰²è³‡æ–™é›†ï¼ˆ50,000 è¨“ç·´ / 10,000 é©—è­‰ / 10,000 æ¸¬è©¦ï¼‰
- è¨“ç·´å¤šç¨®åˆ†é¡å™¨ï¼ˆRandom Forest, Extra Trees, SVMï¼‰
- ä½¿ç”¨ Soft Voting å»ºç«‹ Ensemble
- è©•ä¼°ä¸¦æ¯”è¼ƒæ•ˆèƒ½

### Part 2: Fashion MNIST Dataset
- ä½¿ç”¨ç›¸åŒæ–¹æ³•åœ¨ Fashion MNIST ä¸Šå¯¦é©—
- è¨è«–æ•ˆèƒ½è¡¨ç¾

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å®‰è£ç›¸ä¾å¥—ä»¶

```bash
pip install numpy scikit-learn
```

### åŸ·è¡Œä¸»ç¨‹å¼

```bash
python homework2_ensemble.py

#Final version with bonus methods
python FIN_homework2_ensemble.py

```

é€™æœƒåŸ·è¡Œå®Œæ•´çš„å¯¦é©—ï¼ŒåŒ…æ‹¬ï¼š
- MNIST è³‡æ–™é›†çš„è¨“ç·´å’Œè©•ä¼°
- Fashion MNIST è³‡æ–™é›†çš„è¨“ç·´å’Œè©•ä¼°
- æ•ˆèƒ½æ¯”è¼ƒå’Œåˆ†æ

## ğŸ“ æª”æ¡ˆçµæ§‹

```
.
â”œâ”€â”€ homework2_ensemble.py          # ä¸»ç¨‹å¼ï¼ˆå¿…åšéƒ¨åˆ†ï¼‰
â”œâ”€â”€ bonus_ensemble_methods.py      # Bonus é€²éšæ–¹æ³•
â”œâ”€â”€ FIN_homework2_ensemble.py      # æœ€çµ‚ç‰ˆæœ¬ with bonus methods & æ··æ·†çŸ©é™£
â”œâ”€â”€ task.md                        # ä½œæ¥­è¨˜éŒ„æ–‡ä»¶
â””â”€â”€ README.md                      # æœ¬æª”æ¡ˆ
```

## ğŸ¯ ä¸»è¦åŠŸèƒ½

### homework2_ensemble.py

ä¸»ç¨‹å¼åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **è³‡æ–™è¼‰å…¥èˆ‡åˆ†å‰²**
   ```python
   load_and_split_mnist()
   load_and_split_fashion_mnist()
   ```

2. **è¨“ç·´å€‹åˆ¥åˆ†é¡å™¨**
   ```python
   train_individual_classifiers_mnist()
   ```
   - Random Forest (100 estimators)
   - Extra Trees (100 estimators)
   - SVM (RBF kernel)

3. **å»ºç«‹ Soft Voting Ensemble**
   ```python
   create_soft_voting_ensemble()
   ```

4. **è©•ä¼°èˆ‡æ¯”è¼ƒ**
   ```python
   evaluate_ensemble_mnist()
   ```

### bonus_ensemble_methods.py

é€²éš Ensemble æ–¹æ³•ï¼ˆBonus éƒ¨åˆ†ï¼‰ï¼š

1. **Stacking Ensemble**
   - ä½¿ç”¨ Logistic Regression ä½œç‚º meta-learner
   - 5-fold cross-validation

2. **Weighted Voting**
   - æ ¹æ“šé©—è­‰é›†æ•ˆèƒ½åˆ†é…æ¬Šé‡
   - æ•ˆèƒ½å¥½çš„åˆ†é¡å™¨ç²å¾—æ›´é«˜æ¬Šé‡

3. **Gradient Boosting**
   - ä½¿ç”¨ Gradient Boosting Classifier
   - 100 estimators, learning rate 0.1

## ğŸ“Š é æœŸè¼¸å‡º

ç¨‹å¼åŸ·è¡Œå¾Œæœƒé¡¯ç¤ºï¼š

```
==================================================================
HOMEWORK 2: ENSEMBLE LEARNING
==================================================================

### PART 1: MNIST DATASET ###

Loading MNIST dataset...
Training set: (50000, 784)
Validation set: (10000, 784)
Test set: (10000, 784)

==================================================================
Training Individual Classifiers on MNIST
==================================================================

[1/3] Training Random Forest...
Random Forest - Validation Accuracy: 0.9XXX (Time: XX.XXs)

[2/3] Training Extra Trees...
Extra Trees - Validation Accuracy: 0.9XXX (Time: XX.XXs)

[3/3] Training SVM...
SVM - Validation Accuracy: 0.9XXX (Time: XX.XXs)

==================================================================
Creating Soft Voting Ensemble
==================================================================

Training Soft Voting Ensemble...
Ensemble - Validation Accuracy: 0.9XXX
Ensemble - Test Accuracy: 0.9XXX

==================================================================
Performance Comparison on Test Set
==================================================================
Random Forest        - Val: 0.9XXX, Test: 0.9XXX
Extra Trees          - Val: 0.9XXX, Test: 0.9XXX
SVM                  - Val: 0.9XXX, Test: 0.9XXX
Soft Voting Ensemble - Val: 0.9XXX, Test: 0.9XXX

Improvement over best individual: 0.0XXX (X.XX%)

### PART 2: FASHION MNIST DATASET ###
...
```

## ğŸ”¬ æŠ€è¡“ç´°ç¯€

### Soft Voting åŸç†

Soft Voting ä½¿ç”¨æ¯å€‹åˆ†é¡å™¨çš„é æ¸¬æ©Ÿç‡ï¼š

1. æ¯å€‹åˆ†é¡å™¨è¼¸å‡ºé¡åˆ¥æ©Ÿç‡åˆ†å¸ƒ
2. è¨ˆç®—æ‰€æœ‰åˆ†é¡å™¨çš„å¹³å‡æ©Ÿç‡
3. é¸æ“‡å¹³å‡æ©Ÿç‡æœ€é«˜çš„é¡åˆ¥

æ•¸å­¸è¡¨ç¤ºï¼š
```
P(class=c) = (1/N) * Î£ P_i(class=c)
```

å…¶ä¸­ N æ˜¯åˆ†é¡å™¨æ•¸é‡ï¼ŒP_i æ˜¯ç¬¬ i å€‹åˆ†é¡å™¨çš„é æ¸¬æ©Ÿç‡ã€‚

### ç‚ºä»€éº¼ Ensemble æ•ˆæœæ›´å¥½ï¼Ÿ

1. **é™ä½ Variance**: å¤šå€‹æ¨¡å‹çš„å¹³å‡æ¸›å°‘éæ“¬åˆ
2. **äº’è£œæ€§**: ä¸åŒæ¼”ç®—æ³•æ•æ‰ä¸åŒçš„æ¨¡å¼
3. **éŒ¯èª¤ç³¾æ­£**: å–®ä¸€æ¨¡å‹çš„éŒ¯èª¤å¯èƒ½è¢«å…¶ä»–æ¨¡å‹ç³¾æ­£
4. **ç©©å®šæ€§**: å°è³‡æ–™è®ŠåŒ–æ›´ç©©å¥

## ğŸ Bonus å¯¦ä½œ

è¦ä½¿ç”¨ Bonus æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¸»ç¨‹å¼ä¸­åŠ å…¥ï¼š

```python
from bonus_ensemble_methods import run_bonus_experiments

# åœ¨è¨“ç·´å®Œå€‹åˆ¥åˆ†é¡å™¨å¾Œ
bonus_results = run_bonus_experiments(
    X_train, y_train, X_val, y_val, X_test, y_test, classifiers
)
```

## âš™ï¸ åƒæ•¸èª¿æ•´

å¯ä»¥èª¿æ•´çš„åƒæ•¸ï¼š

- **n_estimators**: Random Forest å’Œ Extra Trees çš„æ¨¹æ•¸é‡
- **kernel**: SVM çš„æ ¸å‡½æ•¸ï¼ˆ'rbf', 'linear', 'poly'ï¼‰
- **voting**: æŠ•ç¥¨æ–¹å¼ï¼ˆ'soft' æˆ– 'hard'ï¼‰
- **random_state**: éš¨æ©Ÿç¨®å­ï¼ˆç¢ºä¿å¯é‡ç¾æ€§ï¼‰

## ğŸ“ æ³¨æ„äº‹é …

1. **åŸ·è¡Œæ™‚é–“**: å®Œæ•´åŸ·è¡Œå¯èƒ½éœ€è¦ 10-30 åˆ†é˜ï¼Œå–æ±ºæ–¼ç¡¬é«”
2. **è¨˜æ†¶é«”**: éœ€è¦è‡³å°‘ 4GB RAM
3. **SVM è¨“ç·´**: ç”±æ–¼è¨ˆç®—æˆæœ¬ï¼Œä½¿ç”¨éƒ¨åˆ†è³‡æ–™è¨“ç·´
4. **Bonus æ–¹æ³•**: ç‚ºäº†åŠ é€Ÿï¼Œä½¿ç”¨è¼ƒå°‘çš„è¨“ç·´è³‡æ–™

## ğŸ” æ•ˆèƒ½å„ªåŒ–å»ºè­°

å¦‚æœåŸ·è¡Œå¤ªæ…¢ï¼Œå¯ä»¥ï¼š

1. æ¸›å°‘ estimators æ•¸é‡ï¼ˆä¾‹å¦‚å¾ 100 é™åˆ° 50ï¼‰
2. ä½¿ç”¨æ›´å°‘çš„è¨“ç·´è³‡æ–™
3. ç§»é™¤ SVMï¼ˆæœ€æ…¢çš„åˆ†é¡å™¨ï¼‰
4. ä½¿ç”¨ `n_jobs=-1` å•Ÿç”¨å¹³è¡Œè™•ç†

## ğŸ“š åƒè€ƒè³‡æ–™

- [Scikit-learn Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html)
- [Voting Classifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)
- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist)


