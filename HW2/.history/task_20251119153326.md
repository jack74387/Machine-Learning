# Homework-2: Ensemble Learning 作業記錄

## 作業要求

這是一個關於 **Multiclass Classification** 的 Ensemble Learning 作業，分為兩個部分：

### Part 1: MNIST Dataset
1. 載入 MNIST 資料集，分割為：
   - Training set: 50,000 筆
   - Validation set: 10,000 筆
   - Test set: 10,000 筆

2. 訓練多個分類器：
   - Random Forest
   - Extra Trees
   - SVM

3. 使用 **Soft Voting** 將這些分類器組合成 ensemble
   - 在 validation set 上找到最佳組合
   - 在 test set 上評估效能
   - 討論 ensemble 相比個別分類器的改善程度

4. (Bonus) 嘗試其他 ensemble learning 方法來進一步提升效能

### Part 2: Fashion MNIST Dataset
1. 使用相同的個別分類器和 ensemble 方法
2. 討論在 Fashion MNIST 上的效能表現

## 實作方法：Taskmaster 方法

Taskmaster 方法是一種系統化的專案管理方式，將複雜任務分解為可管理的步驟。

### 實作架構

```
homework2_ensemble.py
├── Part 1: MNIST Dataset
│   ├── load_and_split_mnist()          # 載入並分割資料
│   ├── train_individual_classifiers()   # 訓練個別分類器
│   ├── create_soft_voting_ensemble()    # 建立 soft voting ensemble
│   └── evaluate_ensemble()              # 評估並比較效能
│
└── Part 2: Fashion MNIST Dataset
    ├── load_and_split_fashion_mnist()   # 載入並分割資料
    └── run_fashion_mnist_experiment()   # 執行相同實驗
```

## 程式碼說明

### 1. 資料載入與分割

```python
def load_and_split_mnist():
    # 使用 sklearn 的 fetch_openml 載入 MNIST
    # 分割為 50,000 / 10,000 / 10,000
    # 使用 stratify 確保類別分布均勻
```

### 2. 訓練個別分類器

實作了三種分類器：

- **Random Forest**: 100 棵樹，使用所有 CPU 核心平行訓練
- **Extra Trees**: 100 棵樹，隨機性更高
- **SVM**: 使用 RBF kernel，由於計算成本高，使用部分資料訓練

每個分類器都會：
- 在 training set 上訓練
- 在 validation set 上評估
- 記錄訓練時間和準確率

### 3. Soft Voting Ensemble

```python
def create_soft_voting_ensemble(classifiers):
    # 使用 VotingClassifier 結合所有分類器
    # voting='soft' 表示使用機率投票
    # 每個分類器輸出類別機率，取平均後選擇最高機率的類別
```

**Soft Voting 原理**：
- 每個分類器預測每個類別的機率
- Ensemble 計算所有分類器的平均機率
- 選擇平均機率最高的類別作為最終預測

### 4. 效能評估與比較

程式會輸出：
- 每個個別分類器在 validation 和 test set 的準確率
- Ensemble 在 validation 和 test set 的準確率
- Ensemble 相比最佳個別分類器的改善幅度

### 5. Fashion MNIST 實驗

使用完全相同的流程和參數，在 Fashion MNIST 資料集上重複實驗。

## 執行方式

### 基本執行

```bash
# 安裝相依套件
pip install -r requirements.txt

# 執行主程式
python homework2_ensemble.py
```

### 執行 Bonus 方法

```python
# 在主程式中加入以下程式碼
from bonus_ensemble_methods import run_bonus_experiments

# 執行進階方法
bonus_results = run_bonus_experiments(
    X_train, y_train, X_val, y_val, X_test, y_test, classifiers
)
```

## 預期輸出

程式會顯示：

1. **資料載入資訊**
   - 各資料集的大小
   - 訓練集：(50000, 784)
   - 驗證集：(10000, 784)
   - 測試集：(10000, 784)

2. **個別分類器訓練過程**
   - Random Forest: 通常達到 96-97% 準確率
   - Extra Trees: 通常達到 96-97% 準確率
   - SVM: 通常達到 94-95% 準確率（使用部分資料）
   - 訓練時間：RF 和 ET 約 30-60 秒，SVM 約 60-120 秒

3. **Ensemble 訓練與評估**
   - Soft Voting Ensemble 通常達到 97-98% 準確率
   - 比最佳個別分類器提升 0.5-1%

4. **效能比較表**
   ```
   Random Forest        - Val: 0.9650, Test: 0.9640
   Extra Trees          - Val: 0.9670, Test: 0.9660
   SVM                  - Val: 0.9450, Test: 0.9440
   Soft Voting Ensemble - Val: 0.9720, Test: 0.9710
   
   Improvement: +0.0050 (+0.50%)
   ```

5. **最終總結**
   - MNIST: Ensemble Test Accuracy ≈ 0.97
   - Fashion MNIST: Ensemble Test Accuracy ≈ 0.88-0.90
   - Fashion MNIST 較難，因為類別間相似度較高

## 關鍵技術點

### Soft Voting vs Hard Voting

- **Hard Voting**: 每個分類器投一票，多數決
- **Soft Voting**: 使用機率平均，通常效果更好
  - 需要分類器支援 `predict_proba()`
  - 考慮了預測的信心程度

### 為什麼 Ensemble 效果更好？

1. **降低 Variance**: 結合多個模型可以減少過擬合
2. **互補性**: 不同演算法有不同的偏好和錯誤模式
3. **穩定性**: 單一模型的錯誤可能被其他模型糾正

### 資料分割策略

使用 `stratify` 參數確保：
- 訓練、驗證、測試集的類別分布一致
- 避免某些類別在某個集合中過少或過多

## Bonus 改進方向

已在 `bonus_ensemble_methods.py` 中實作的進階方法：

### 1. Stacking (Blending)
```python
create_stacking_ensemble(X_train, y_train, X_val, y_val)
```
- **原理**: 使用一個 meta-learner（Logistic Regression）學習如何組合基礎分類器
- **優勢**: 可以學習最佳的組合方式，而非簡單平均
- **實作**: 使用 5-fold CV 生成 meta-features
- **預期效能**: 通常比 Soft Voting 提升 0.2-0.5%

### 2. Weighted Voting
```python
create_weighted_voting_ensemble(classifiers, X_val, y_val)
```
- **原理**: 根據 validation 效能給予不同權重
- **優勢**: 效能好的分類器有更大影響力
- **實作**: 權重 = 各分類器的 validation accuracy（正規化）
- **預期效能**: 略優於等權重的 Soft Voting

### 3. Gradient Boosting
```python
train_gradient_boosting(X_train, y_train, X_val, y_val)
```
- **原理**: 序列式訓練，每個新模型修正前一個的錯誤
- **優勢**: 強大的單一模型，可與其他方法比較
- **實作**: 100 estimators, learning_rate=0.1, max_depth=3
- **預期效能**: MNIST 約 96-97%

### 其他可嘗試的方法

4. **增加更多分類器**
   - k-NN (k-Nearest Neighbors)
   - Neural Networks (MLPClassifier)
   - Naive Bayes

5. **特徵工程**
   - PCA 降維（減少到 50-100 維）
   - 特徵標準化（StandardScaler）
   - 特徵選擇

6. **超參數優化**
   - Grid Search 或 Random Search
   - 針對每個分類器找最佳參數

7. **資料增強**
   - 旋轉、平移、縮放圖片
   - 增加訓練資料多樣性

## 注意事項

1. **計算時間**: SVM 訓練較慢，程式中使用了部分資料
2. **記憶體使用**: MNIST 資料集較大，確保有足夠記憶體
3. **隨機種子**: 使用 `random_state=42` 確保結果可重現

## 學習重點

1. 理解 Ensemble Learning 的原理和優勢
2. 掌握 Soft Voting 的實作方式
3. 學會比較和評估不同模型的效能
4. 了解如何在不同資料集上應用相同方法

## 專案檔案清單

```
.
├── homework2_ensemble.py          # 主程式（Part 1 & 2）
├── bonus_ensemble_methods.py      # Bonus 進階方法
├── test_quick.py                  # 快速測試腳本
├── requirements.txt               # Python 套件需求
├── task.md                        # 本檔案（作業記錄）
└── README.md                      # 專案說明文件
```

## 使用流程

### 步驟 1: 快速測試（建議先執行）
```bash
python test_quick.py
```
- 使用小量資料快速驗證程式正確性
- 執行時間約 1-2 分鐘
- 確認環境設定無誤

### 步驟 2: 完整實驗
```bash
python homework2_ensemble.py
```
- 執行完整的 MNIST 和 Fashion MNIST 實驗
- 執行時間約 15-30 分鐘
- 產生完整的效能報告

### 步驟 3: Bonus 方法（選擇性）
修改 `homework2_ensemble.py`，在主函數中加入：
```python
from bonus_ensemble_methods import run_bonus_experiments

# 在 Part 1 結束後加入
bonus_results = run_bonus_experiments(
    X_train_mnist, y_train_mnist, 
    X_val_mnist, y_val_mnist, 
    X_test_mnist, y_test_mnist, 
    classifiers_mnist
)
```

## 實驗結果分析

### MNIST Dataset 預期結果

| 分類器 | Validation Acc | Test Acc | 訓練時間 |
|--------|---------------|----------|---------|
| Random Forest | 0.965 | 0.964 | ~40s |
| Extra Trees | 0.967 | 0.966 | ~35s |
| SVM | 0.945 | 0.944 | ~90s |
| **Soft Voting** | **0.972** | **0.971** | ~5s |

**觀察**:
- Ensemble 比最佳個別分類器提升約 0.5%
- Extra Trees 通常表現最好
- SVM 雖然較慢，但仍有貢獻

### Fashion MNIST Dataset 預期結果

| 分類器 | Validation Acc | Test 
