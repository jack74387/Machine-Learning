# Homework-2: Ensemble Learning 作業記錄

## 作業要求

這是一個關於 **Multiclass Classification** 的 Ensemble Learning 作業，分為兩個部分：

### Part 1: MNIST Dataset
1. 載入 MNIST 資料集，分割為：
   - Training set: 50,000 筆
   - Validation set: 10,000 筆
   - Test set: 10,000 筆

2. 訓練多個分類器：
   - Random Forest
   - Extra Trees
   - SVM

3. 使用 **Soft Voting** 將這些分類器組合成 ensemble
   - 在 validation set 上找到最佳組合
   - 在 test set 上評估效能
   - 討論 ensemble 相比個別分類器的改善程度

4. (Bonus) 嘗試其他 ensemble learning 方法來進一步提升效能

### Part 2: Fashion MNIST Dataset
1. 使用相同的個別分類器和 ensemble 方法
2. 討論在 Fashion MNIST 上的效能表現

## 實作方法：Taskmaster 方法

Taskmaster 方法是一種系統化的專案管理方式，將複雜任務分解為可管理的步驟。

### 實作架構

```
homework2_ensemble.py
├── Part 1: MNIST Dataset
│   ├── load_and_split_mnist()          # 載入並分割資料
│   ├── train_individual_classifiers()   # 訓練個別分類器
│   ├── create_soft_voting_ensemble()    # 建立 soft voting ensemble
│   └── evaluate_ensemble()              # 評估並比較效能
│
└── Part 2: Fashion MNIST Dataset
    ├── load_and_split_fashion_mnist()   # 載入並分割資料
    └── run_fashion_mnist_experiment()   # 執行相同實驗
```

## 程式碼說明

### 1. 資料載入與分割

```python
def load_and_split_mnist():
    # 使用 sklearn 的 fetch_openml 載入 MNIST
    # 分割為 50,000 / 10,000 / 10,000
    # 使用 stratify 確保類別分布均勻
```

### 2. 訓練個別分類器

實作了三種分類器：

- **Random Forest**: 100 棵樹，使用所有 CPU 核心平行訓練
- **Extra Trees**: 100 棵樹，隨機性更高
- **SVM**: 使用 RBF kernel，由於計算成本高，使用部分資料訓練

每個分類器都會：
- 在 training set 上訓練
- 在 validation set 上評估
- 記錄訓練時間和準確率

### 3. Soft Voting Ensemble

```python
def create_soft_voting_ensemble(classifiers):
    # 使用 VotingClassifier 結合所有分類器
    # voting='soft' 表示使用機率投票
    # 每個分類器輸出類別機率，取平均後選擇最高機率的類別
```

**Soft Voting 原理**：
- 每個分類器預測每個類別的機率
- Ensemble 計算所有分類器的平均機率
- 選擇平均機率最高的類別作為最終預測

### 4. 效能評估與比較

程式會輸出：
- 每個個別分類器在 validation 和 test set 的準確率
- Ensemble 在 validation 和 test set 的準確率
- Ensemble 相比最佳個別分類器的改善幅度

### 5. Fashion MNIST 實驗

使用完全相同的流程和參數，在 Fashion MNIST 資料集上重複實驗。

## 執行方式

```bash
python homework2_ensemble.py
```

## 預期輸出

程式會顯示：

1. **資料載入資訊**
   - 各資料集的大小

2. **個別分類器訓練過程**
   - 訓練時間
   - Validation 準確率

3. **Ensemble 訓練與評估**
   - Ensemble 的 validation 和 test 準確率

4. **效能比較表**
   - 所有分類器的效能對比
   - Ensemble 的改善幅度

5. **最終總結**
   - MNIST 和 Fashion MNIST 的最終結果

## 關鍵技術點

### Soft Voting vs Hard Voting

- **Hard Voting**: 每個分類器投一票，多數決
- **Soft Voting**: 使用機率平均，通常效果更好
  - 需要分類器支援 `predict_proba()`
  - 考慮了預測的信心程度

### 為什麼 Ensemble 效果更好？

1. **降低 Variance**: 結合多個模型可以減少過擬合
2. **互補性**: 不同演算法有不同的偏好和錯誤模式
3. **穩定性**: 單一模型的錯誤可能被其他模型糾正

### 資料分割策略

使用 `stratify` 參數確保：
- 訓練、驗證、測試集的類別分布一致
- 避免某些類別在某個集合中過少或過多

## Bonus 改進方向

可以嘗試的其他 ensemble 方法：

1. **Stacking (Blending)**
   - 使用一個 meta-learner 學習如何組合基礎分類器
   - 可能比簡單投票更有效

2. **Bagging with Different Algorithms**
   - 對每種演算法使用不同的資料子集

3. **Weighted Voting**
   - 根據 validation 效能給予不同權重

4. **增加更多分類器**
   - Gradient Boosting
   - Neural Networks
   - k-NN

5. **特徵工程**
   - PCA 降維
   - 特徵標準化

## 注意事項

1. **計算時間**: SVM 訓練較慢，程式中使用了部分資料
2. **記憶體使用**: MNIST 資料集較大，確保有足夠記憶體
3. **隨機種子**: 使用 `random_state=42` 確保結果可重現

## 學習重點

1. 理解 Ensemble Learning 的原理和優勢
2. 掌握 Soft Voting 的實作方式
3. 學會比較和評估不同模型的效能
4. 了解如何在不同資料集上應用相同方法

---

**作業完成日期**: 2025-11-19
**實作方法**: Taskmaster
**程式語言**: Python
**主要套件**: scikit-learn, numpy
